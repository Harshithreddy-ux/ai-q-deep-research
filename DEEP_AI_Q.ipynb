{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c974332b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.0.5)\n",
      "Requirement already satisfied: langchain_nvidia_ai_endpoints in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.0.0)\n",
      "Requirement already satisfied: langchain_community in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.4.1)\n",
      "Requirement already satisfied: tavily-python in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.7.17)\n",
      "Requirement already satisfied: rich in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (14.2.0)\n",
      "Requirement already satisfied: langchain-core>=0.1 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langgraph) (1.2.6)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langgraph) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langgraph) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langgraph) (0.3.1)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langgraph) (2.12.5)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langgraph) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.12.1)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11.5)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain_nvidia_ai_endpoints) (3.13.3)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain_nvidia_ai_endpoints) (1.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (1.22.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain-core>=0.1->langgraph) (0.6.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain-core>=0.1->langgraph) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain-core>=0.1->langgraph) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (4.12.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic>=2.7.4->langgraph) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain_community) (1.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain_community) (2.0.45)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain_community) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain_community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain_community) (2.3.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.6.2)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: tiktoken>=0.5.1 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tavily-python) (0.12.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from rich) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from rich) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\msi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tiktoken>=0.5.1->tavily-python) (2025.11.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\msi\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langgraph langchain_nvidia_ai_endpoints langchain_community tavily-python rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef620e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Found Stable Model: meta/llama-</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">3.1</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">-70b-instruct</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m✅ Found Stable Model: meta/llama-\u001b[0m\u001b[1;32m3.1\u001b[0m\u001b[1;32m-70b-instruct\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msi\\AppData\\Local\\Temp\\ipykernel_14476\\1580863221.py:58: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the `langchain-tavily package and should be used instead. To use it run `pip install -U `langchain-tavily` and import as `from `langchain_tavily import TavilySearch``.\n",
      "  search_tool = TavilySearchResults(max_results=3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">────────────────────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">NVIDIA AI-Q STARTING</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ───────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m────────────────────────────────────────────── \u001b[0m\u001b[1;31mNVIDIA AI-Q STARTING\u001b[0m\u001b[92m ───────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">C:\\Users\\msi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Py\n",
       "thon311\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "C:\\Users\\msi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Py\n",
       "thon311\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────────────── FINAL RESEARCH REPORT ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> **Deep Research Report:**                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> **Comparing NVIDIA Blackwell GB200 Performance vs H100 for MoE Models**                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> **Executive Summary:**                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> This report provides an in-depth comparison of the performance of NVIDIA's Blackwell GB200 and H100 GPUs when   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> running Mixture of Experts (MoE) models. Our analysis is based on a comprehensive review of publicly available  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> benchmarks, technical deep dives, and expert opinions. We examine the performance differences between the two   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> GPUs in terms of training speed, power efficiency, and memory requirements. Our findings indicate that the      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Blackwell GB200 outperforms the H100 in MoE model training, with significant advantages in terms of power       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> efficiency and memory capacity.                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> **Introduction:**                                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> MoE models have become increasingly popular in the field of artificial intelligence, particularly in natural    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> language processing tasks. As the demand for more efficient and scalable MoE models grows, the need for         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> high-performance computing hardware that can handle these complex workloads has become more pressing. NVIDIA's  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> H100 and Blackwell GB200 GPUs are two of the most powerful GPUs currently available for MoE model training. In  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> this report, we will compare the performance of these two GPUs and provide insights into their strengths and    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> weaknesses.                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> **Training Speed:**                                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> The Blackwell GB200 has been shown to outperform the H100 in MoE model training speed. According to a benchmark <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> published by NVIDIA, the GB200 achieved a 4x training speedup over the H100 when running a                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> 1.8-trillion-parameter GPT-MoE-1.8T model. This significant performance advantage is attributed to the GB200's  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> higher floating-point operation capacity and improved interconnect technology.                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> **Power Efficiency:**                                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> The Blackwell GB200 also excels in terms of power efficiency, with a claimed 25x improvement over the H100.     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> This is largely due to the GB200's use of a more efficient FP4 format, which reduces power consumption while    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> maintaining high Performance. According to a report by Adrian Co, the GB200's per-GPU benchmark claim is 30x    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> higher than the H100's, with a significant portion of this gain attributed to the improved power efficiency.    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> **Memory Requirements:**                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> The Blackwell GB200 has a higher memory capacity than the H100, which is essential for MoE model training. The  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> GB200's NVL-36 system comes with over 6TB of high-bandwidth GPU memory, while the H100-based systems have a     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> total of about 5TB of GPU memory. This increased memory capacity allows the GB200 to handle larger models and   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> more complex workloads.                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> **Interconnect Technology:**                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> The interconnect technology used in the Blackwell GB200 also contributes to its improved performance. The GB200 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> uses an interconnect that provides 900GB/s of coherent bandwidth, which is significantly higher than the H100's <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> NVlink interconnect. This improved interconnect technology enables the GB200 to scale more efficiently and      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> handle larger models.                                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> **Conclusion:**                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> In conclusion, our analysis indicates that the NVIDIA Blackwell GB200 outperforms the H100 in MoE model         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> training, with significant advantages in terms of training speed, power efficiency, and memory capacity. The    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> GB200's improved floating-point operation capacity, power-efficient FP4 format, and advanced interconnect       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> technology make it a more attractive option for MoE model training workloads. However, it is essential to note  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> that the H100 is still a powerful GPU that can deliver high performance in various applications.                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> **Recommendations:**                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Based on our findings, we recommend the following:                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> * For MoE model training workloads, the NVIDIA Blackwell GB200 is the preferred option due to its superior      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> performance, power efficiency, and memory capacity.                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> * For applications that require high-performance computing but do not require the level of performance provided <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> by the GB200, the H100 is still a viable option.                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> * Further research is needed to explore the optimal configurations and workloads for both GPUs to fully utilize <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> their capabilities.                                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> **Future Research Directions:**                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Future research should focus on:                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> * Exploring the optimal configurations and workloads for both GPUs to fully utilize their capabilities.         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> * Investigating the potential applications of the Blackwell GB200 in other domains, such as computer vision and <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> recommender systems.                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> * Comparing the performance of the Blackwell GB200 with other GPUs, such as the AMD MI200 and the Google TPU.   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> By continuing to explore the capabilities and limitations of these powerful GPUs, we can better understand      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> their potential to drive innovation in the field of artificial intelligence.                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m FINAL RESEARCH REPORT \u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m **Deep Research Report:**                                                                                       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m **Comparing NVIDIA Blackwell GB200 Performance vs H100 for MoE Models**                                         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m **Executive Summary:**                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m This report provides an in-depth comparison of the performance of NVIDIA's Blackwell GB200 and H100 GPUs when   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m running Mixture of Experts (MoE) models. Our analysis is based on a comprehensive review of publicly available  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m benchmarks, technical deep dives, and expert opinions. We examine the performance differences between the two   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m GPUs in terms of training speed, power efficiency, and memory requirements. Our findings indicate that the      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Blackwell GB200 outperforms the H100 in MoE model training, with significant advantages in terms of power       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m efficiency and memory capacity.                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m **Introduction:**                                                                                               \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m MoE models have become increasingly popular in the field of artificial intelligence, particularly in natural    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m language processing tasks. As the demand for more efficient and scalable MoE models grows, the need for         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m high-performance computing hardware that can handle these complex workloads has become more pressing. NVIDIA's  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m H100 and Blackwell GB200 GPUs are two of the most powerful GPUs currently available for MoE model training. In  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m this report, we will compare the performance of these two GPUs and provide insights into their strengths and    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m weaknesses.                                                                                                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m **Training Speed:**                                                                                             \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m The Blackwell GB200 has been shown to outperform the H100 in MoE model training speed. According to a benchmark \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m published by NVIDIA, the GB200 achieved a 4x training speedup over the H100 when running a                      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m 1.8-trillion-parameter GPT-MoE-1.8T model. This significant performance advantage is attributed to the GB200's  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m higher floating-point operation capacity and improved interconnect technology.                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m **Power Efficiency:**                                                                                           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m The Blackwell GB200 also excels in terms of power efficiency, with a claimed 25x improvement over the H100.     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m This is largely due to the GB200's use of a more efficient FP4 format, which reduces power consumption while    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m maintaining high Performance. According to a report by Adrian Co, the GB200's per-GPU benchmark claim is 30x    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m higher than the H100's, with a significant portion of this gain attributed to the improved power efficiency.    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m **Memory Requirements:**                                                                                        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m The Blackwell GB200 has a higher memory capacity than the H100, which is essential for MoE model training. The  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m GB200's NVL-36 system comes with over 6TB of high-bandwidth GPU memory, while the H100-based systems have a     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m total of about 5TB of GPU memory. This increased memory capacity allows the GB200 to handle larger models and   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m more complex workloads.                                                                                         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m **Interconnect Technology:**                                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m The interconnect technology used in the Blackwell GB200 also contributes to its improved performance. The GB200 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m uses an interconnect that provides 900GB/s of coherent bandwidth, which is significantly higher than the H100's \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m NVlink interconnect. This improved interconnect technology enables the GB200 to scale more efficiently and      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m handle larger models.                                                                                           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m **Conclusion:**                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m In conclusion, our analysis indicates that the NVIDIA Blackwell GB200 outperforms the H100 in MoE model         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m training, with significant advantages in terms of training speed, power efficiency, and memory capacity. The    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m GB200's improved floating-point operation capacity, power-efficient FP4 format, and advanced interconnect       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m technology make it a more attractive option for MoE model training workloads. However, it is essential to note  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m that the H100 is still a powerful GPU that can deliver high performance in various applications.                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m **Recommendations:**                                                                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Based on our findings, we recommend the following:                                                              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m * For MoE model training workloads, the NVIDIA Blackwell GB200 is the preferred option due to its superior      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m performance, power efficiency, and memory capacity.                                                             \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m * For applications that require high-performance computing but do not require the level of performance provided \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m by the GB200, the H100 is still a viable option.                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m * Further research is needed to explore the optimal configurations and workloads for both GPUs to fully utilize \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m their capabilities.                                                                                             \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m **Future Research Directions:**                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Future research should focus on:                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m * Exploring the optimal configurations and workloads for both GPUs to fully utilize their capabilities.         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m * Investigating the potential applications of the Blackwell GB200 in other domains, such as computer vision and \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m recommender systems.                                                                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m * Comparing the performance of the Blackwell GB200 with other GPUs, such as the AMD MI200 and the Google TPU.   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m By continuing to explore the capabilities and limitations of these powerful GPUs, we can better understand      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m their potential to drive innovation in the field of artificial intelligence.                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "from typing import Annotated, List, TypedDict, Literal\n",
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "# Your provided API keys\n",
    "os.environ[\"NVIDIA_API_KEY\"] = \"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\"\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"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\"\n",
    "\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "console = Console()\n",
    "\n",
    "# --- 2. DYNAMIC MODEL DISCOVERY (Fixes the 404 Error) ---\n",
    "def find_working_model():\n",
    "    \"\"\"Queries the NVIDIA API for models available to YOUR account\"\"\"\n",
    "    try:\n",
    "        available_models = ChatNVIDIA.get_available_models()\n",
    "        model_ids = [m.id for m in available_models]\n",
    "        \n",
    "        # Priority list of top reasoning models for research\n",
    "        priorities = [\n",
    "            \"nvidia/llama-3.1-nemotron-70b-instruct\",\n",
    "            \"meta/llama-3.1-70b-instruct\",\n",
    "            \"meta/llama-3.1-8b-instruct\",\n",
    "            \"nvidia/nemotron-4-340b-instruct\"\n",
    "        ]\n",
    "        \n",
    "        for p in priorities:\n",
    "            if p in model_ids:\n",
    "                console.print(f\"[bold green]✅ Found Stable Model: {p}\")\n",
    "                return p\n",
    "        \n",
    "        # Fallback to the first available chat model\n",
    "        console.print(f\"[bold yellow]⚠️ Target model not found. Using fallback: {model_ids[0]}\")\n",
    "        return model_ids[0]\n",
    "    except Exception as e:\n",
    "        console.print(f\"[bold red]❌ Could not list models: {e}\")\n",
    "        return \"meta/llama-3.1-8b-instruct\" # Hard fallback\n",
    "\n",
    "SELECTED_MODEL = find_working_model()\n",
    "\n",
    "# --- 3. AGENT DEFINITION ---\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[List, add_messages]\n",
    "    research_plan: List[str]\n",
    "    collected_data: List[str]\n",
    "    steps_taken: int\n",
    "\n",
    "llm = ChatNVIDIA(model=SELECTED_MODEL)\n",
    "search_tool = TavilySearchResults(max_results=3)\n",
    "\n",
    "# --- NODES ---\n",
    "def planner_node(state: AgentState):\n",
    "    query = state[\"messages\"][0].content\n",
    "    with console.status(\"[bold green]🧠 Planning research...\", spinner=\"dots\"):\n",
    "        prompt = f\"Break this query into 3 specific research goals: {query}. Output as a numbered list.\"\n",
    "        response = llm.invoke([SystemMessage(content=\"You are a Technical Researcher.\"), HumanMessage(content=prompt)])\n",
    "        # Robust parsing for list items\n",
    "        tasks = re.findall(r'\\d+\\.\\s*(.*)', response.content)\n",
    "        if not tasks: tasks = [query] # Safety fallback\n",
    "    return {\"research_plan\": tasks[:3], \"steps_taken\": 0}\n",
    "\n",
    "def researcher_node(state: AgentState):\n",
    "    idx = state[\"steps_taken\"]\n",
    "    task = state[\"research_plan\"][idx % len(state[\"research_plan\"])]\n",
    "    with console.status(f\"[bold cyan]🔍 Researching Goal {idx+1}: {task}\", spinner=\"earth\"):\n",
    "        results = search_tool.invoke({\"query\": task})\n",
    "    return {\"collected_data\": [f\"Goal: {task}\\nResult: {results}\"], \"steps_taken\": idx + 1}\n",
    "\n",
    "def writer_node(state: AgentState):\n",
    "    with console.status(\"[bold magenta]✍️ Writing Deep Analysis...\", spinner=\"bouncingBar\"):\n",
    "        context = \"\\n---\\n\".join(state[\"collected_data\"])\n",
    "        query = state[\"messages\"][0].content\n",
    "        prompt = f\"Using this data:\\n{context}\\n\\nWrite a deep research report on: {query}\"\n",
    "        response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    console.print(Panel(response.content, title=\"FINAL RESEARCH REPORT\", border_style=\"green\"))\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def router(state: AgentState) -> Literal[\"researcher_node\", \"writer_node\"]:\n",
    "    if state[\"steps_taken\"] < len(state.get(\"research_plan\", [])):\n",
    "        return \"researcher_node\"\n",
    "    return \"writer_node\"\n",
    "\n",
    "# --- 4. ASSEMBLE GRAPH ---\n",
    "builder = StateGraph(AgentState)\n",
    "builder.add_node(\"planner_node\", planner_node)\n",
    "builder.add_node(\"researcher_node\", researcher_node)\n",
    "builder.add_node(\"writer_node\", writer_node)\n",
    "\n",
    "builder.add_edge(START, \"planner_node\")\n",
    "builder.add_edge(\"planner_node\", \"researcher_node\")\n",
    "builder.add_conditional_edges(\"researcher_node\", router)\n",
    "builder.add_edge(\"writer_node\", END)\n",
    "\n",
    "app = builder.compile()\n",
    "\n",
    "# --- 5. EXECUTE ---\n",
    "user_query = \"Compare NVIDIA Blackwell GB200 performance vs H100 for MoE models.\"\n",
    "console.rule(\"[bold red]NVIDIA AI-Q STARTING\")\n",
    "for output in app.stream({\"messages\": [HumanMessage(content=user_query)]}):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22827f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34145571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">NVIDIA AI-Q v2: DEEP VERIFICATION MODE</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ──────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────── \u001b[0m\u001b[1;34mNVIDIA AI-Q v2: DEEP VERIFICATION MODE\u001b[0m\u001b[92m ──────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────────────── FINAL RESEARCH REPORT ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> **Detailed Comparison: NVIDIA Blackwell B200 vs H100 NVLink Bandwidth and Energy Efficiency**                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> **Introduction**                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> In the realm of artificial intelligence and high-performance computing, interconnect bandwidth plays a crucial  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> role in determining the performance and efficiency of data transfer between GPUs. NVIDIA's NVLink technology is <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> a key component in facilitating high-bandwidth, low-latency communication between GPUs. This report provides a  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> detailed comparison of the NVLink bandwidth and energy efficiency of NVIDIA's Blackwell B200 and H100 GPUs.     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> **NVLink Bandwidth Comparison**                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Our research reveals that the NVIDIA Blackwell B200 boasts a significantly higher NVLink bandwidth compared to  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> the H100. The B200's fifth-generation NVLink (NVLink 5) offers a maximum bandwidth of 1.8 TB/s, whereas the     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> H100's NVLink 4.0 has a maximum bandwidth of 900 GB/s. This represents a 100% increase in bandwidth, enabling   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> the B200 to handle more complex workloads and larger datasets.                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> **Number of NVLink Lanes**                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> According to our findings, each NVIDIA Blackwell GPU supports up to 18 NVLink connections, with each connection <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> supporting 100 GB/s. In contrast, the H100 has a lower number of NVLink lanes, resulting in reduced overall     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> bandwidth.                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> **Interconnect Specifications**                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> The B200's NVLink 5 interconnect features 200 Gbps per-link signaling, doubling the per-link bandwidth compared <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> to the H100's NVLink 4. This improved signaling rate contributes to the B200's higher overall bandwidth.        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> **Energy Efficiency**                                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> While the B200's higher performance comes at the cost of increased power consumption (1,000 W TDP vs. 700 W TDP <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> for the H100), our research suggests that the B200's energy efficiency is still competitive. The B200's         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> improved performance and bandwidth enable it to complete tasks more quickly, reducing the overall energy        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> required for computation.                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> ** lĩnh Comparison**                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> To provide a comprehensive understanding of the performance difference between the two GPUs, we can examine the <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> MLPerf benchmarks. The B200 offers 2.2× training and 4× inference performance over the H100, demonstrating its  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> improved capabilities.                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> **Implications for AI and HPC Workloads**                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> The enhanced NVLink bandwidth and energy efficiency of the NVIDIA Blackwell B200 have significant implications  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> for AI and HPC workloads. The increased bandwidth enables faster data transfer and reduced latency, making it   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> an ideal solution for applications such as:                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> 1.  Large-scale deep learning training                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> 2.  High-performance computing simulations                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> 3.  Data analytics and visualization                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> **Conclusion**                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> In conclusion, our research demonstrates that the NVIDIA Blackwell B200 offers superior NVLink bandwidth and    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> energy efficiency compared to the H100. The B200's fifth-generation NVLink, higher number of NVLink lanes, and  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> improved interconnect specifications contribute to its enhanced performance. While the B200's increased power   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> consumption is a consideration, its improved energy efficiency and reduced latency make it an attractive        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> solution for demanding AI and HPC workloads.                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> **Recommendations**                                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Based on our findings, we recommend the NVIDIA Blackwell B200 for applications requiring high NVLink bandwidth  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> and energy efficiency. However, for workloads with lower bandwidth requirements, the H100 may still be a        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> suitable option. Ultimately, the choice between the B200 and H100 will depend on specific use case requirements <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> and constraints.                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> **Future Research Directions**                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Future research should explore the following areas:                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> 1.  In-depth analysis of the B200's NVLink 5 interconnect and its impact on performance                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> 2.  Comparison of the B200's energy efficiency with other high-performance GPUs                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> 3.  Investigations into the implications of the B200's improved performance on specific AI and HPC workloads    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> **References**                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> 1.  Modal. (n.d.). NVIDIA Blackwell. Retrieved from &lt;https://modal.com/blog/nvidia-blackwell&gt;                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> 2.  Civo. (n.d.). Comparing NVIDIA's B200 and H100: What's the difference? Retrieved from                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> &lt;https://www.civo.com/blog/comparing-nvidia-b200-and-h100&gt;                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m FINAL RESEARCH REPORT \u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m **Detailed Comparison: NVIDIA Blackwell B200 vs H100 NVLink Bandwidth and Energy Efficiency**                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m **Introduction**                                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m In the realm of artificial intelligence and high-performance computing, interconnect bandwidth plays a crucial  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m role in determining the performance and efficiency of data transfer between GPUs. NVIDIA's NVLink technology is \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m a key component in facilitating high-bandwidth, low-latency communication between GPUs. This report provides a  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m detailed comparison of the NVLink bandwidth and energy efficiency of NVIDIA's Blackwell B200 and H100 GPUs.     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m **NVLink Bandwidth Comparison**                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Our research reveals that the NVIDIA Blackwell B200 boasts a significantly higher NVLink bandwidth compared to  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m the H100. The B200's fifth-generation NVLink (NVLink 5) offers a maximum bandwidth of 1.8 TB/s, whereas the     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m H100's NVLink 4.0 has a maximum bandwidth of 900 GB/s. This represents a 100% increase in bandwidth, enabling   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m the B200 to handle more complex workloads and larger datasets.                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m **Number of NVLink Lanes**                                                                                      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m According to our findings, each NVIDIA Blackwell GPU supports up to 18 NVLink connections, with each connection \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m supporting 100 GB/s. In contrast, the H100 has a lower number of NVLink lanes, resulting in reduced overall     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m bandwidth.                                                                                                      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m **Interconnect Specifications**                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m The B200's NVLink 5 interconnect features 200 Gbps per-link signaling, doubling the per-link bandwidth compared \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m to the H100's NVLink 4. This improved signaling rate contributes to the B200's higher overall bandwidth.        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m **Energy Efficiency**                                                                                           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m While the B200's higher performance comes at the cost of increased power consumption (1,000 W TDP vs. 700 W TDP \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m for the H100), our research suggests that the B200's energy efficiency is still competitive. The B200's         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m improved performance and bandwidth enable it to complete tasks more quickly, reducing the overall energy        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m required for computation.                                                                                       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m ** lĩnh Comparison**                                                                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m To provide a comprehensive understanding of the performance difference between the two GPUs, we can examine the \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m MLPerf benchmarks. The B200 offers 2.2× training and 4× inference performance over the H100, demonstrating its  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m improved capabilities.                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m **Implications for AI and HPC Workloads**                                                                       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m The enhanced NVLink bandwidth and energy efficiency of the NVIDIA Blackwell B200 have significant implications  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m for AI and HPC workloads. The increased bandwidth enables faster data transfer and reduced latency, making it   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m an ideal solution for applications such as:                                                                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m 1.  Large-scale deep learning training                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m 2.  High-performance computing simulations                                                                      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m 3.  Data analytics and visualization                                                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m **Conclusion**                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m In conclusion, our research demonstrates that the NVIDIA Blackwell B200 offers superior NVLink bandwidth and    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m energy efficiency compared to the H100. The B200's fifth-generation NVLink, higher number of NVLink lanes, and  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m improved interconnect specifications contribute to its enhanced performance. While the B200's increased power   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m consumption is a consideration, its improved energy efficiency and reduced latency make it an attractive        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m solution for demanding AI and HPC workloads.                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m **Recommendations**                                                                                             \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Based on our findings, we recommend the NVIDIA Blackwell B200 for applications requiring high NVLink bandwidth  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m and energy efficiency. However, for workloads with lower bandwidth requirements, the H100 may still be a        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m suitable option. Ultimately, the choice between the B200 and H100 will depend on specific use case requirements \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m and constraints.                                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m **Future Research Directions**                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Future research should explore the following areas:                                                             \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m 1.  In-depth analysis of the B200's NVLink 5 interconnect and its impact on performance                         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m 2.  Comparison of the B200's energy efficiency with other high-performance GPUs                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m 3.  Investigations into the implications of the B200's improved performance on specific AI and HPC workloads    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m **References**                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m 1.  Modal. (n.d.). NVIDIA Blackwell. Retrieved from <https://modal.com/blog/nvidia-blackwell>                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m 2.  Civo. (n.d.). Comparing NVIDIA's B200 and H100: What's the difference? Retrieved from                       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m <https://www.civo.com/blog/comparing-nvidia-b200-and-h100>                                                      \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "\"no spinner called 'scale'\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\rich\\spinner.py:35\u001b[39m, in \u001b[36mSpinner.__init__\u001b[39m\u001b[34m(self, name, text, style, speed)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     spinner = \u001b[43mSPINNERS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[31mKeyError\u001b[39m: 'scale'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 63\u001b[39m\n\u001b[32m     61\u001b[39m user_query = \u001b[33m\"\u001b[39m\u001b[33mDetailed comparison: NVIDIA Blackwell B200 vs H100 NVLink bandwidth and energy efficiency.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     62\u001b[39m console.rule(\u001b[33m\"\u001b[39m\u001b[33m[bold blue]NVIDIA AI-Q v2: DEEP VERIFICATION MODE\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m \u001b[43mapp_v2\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_query\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langgraph\\pregel\\main.py:3068\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3065\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3066\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3068\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3069\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langgraph\\pregel\\main.py:2643\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2641\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2642\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2643\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2644\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2645\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2646\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2653\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langgraph\\pregel\\_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langgraph\\_internal\\_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langgraph\\_internal\\_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mreviewer_node\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Acts as the 'Judge' to check for technical accuracy.\"\"\"\u001b[39;00m\n\u001b[32m     12\u001b[39m report = state[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m][-\u001b[32m1\u001b[39m].content\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mconsole\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m[bold yellow]⚖️ NVIDIA AI-Q is auditing the report...\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspinner\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[32m     14\u001b[39m     prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33m    Act as a Senior NVIDIA Engineer. Review this report for technical accuracy:\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[33m    \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreport\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m \u001b[33m    If anything is missing, list it. If it\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms perfect, say \u001b[39m\u001b[33m'\u001b[39m\u001b[33mAPPROVED\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[33m    \u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     22\u001b[39m     response = llm.invoke([HumanMessage(content=prompt)])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\rich\\console.py:1186\u001b[39m, in \u001b[36mConsole.status\u001b[39m\u001b[34m(self, status, spinner, spinner_style, speed, refresh_per_second)\u001b[39m\n\u001b[32m   1172\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Display a status and spinner.\u001b[39;00m\n\u001b[32m   1173\u001b[39m \n\u001b[32m   1174\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1182\u001b[39m \u001b[33;03m    Status: A Status object that may be used as a context manager.\u001b[39;00m\n\u001b[32m   1183\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1184\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstatus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Status\n\u001b[32m-> \u001b[39m\u001b[32m1186\u001b[39m status_renderable = \u001b[43mStatus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconsole\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspinner\u001b[49m\u001b[43m=\u001b[49m\u001b[43mspinner\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspinner_style\u001b[49m\u001b[43m=\u001b[49m\u001b[43mspinner_style\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspeed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mspeed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrefresh_per_second\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrefresh_per_second\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m status_renderable\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\rich\\status.py:36\u001b[39m, in \u001b[36mStatus.__init__\u001b[39m\u001b[34m(self, status, console, spinner, spinner_style, speed, refresh_per_second)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28mself\u001b[39m.spinner_style = spinner_style\n\u001b[32m     35\u001b[39m \u001b[38;5;28mself\u001b[39m.speed = speed\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[38;5;28mself\u001b[39m._spinner = \u001b[43mSpinner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspinner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mspinner_style\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mspeed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;28mself\u001b[39m._live = Live(\n\u001b[32m     38\u001b[39m     \u001b[38;5;28mself\u001b[39m.renderable,\n\u001b[32m     39\u001b[39m     console=console,\n\u001b[32m     40\u001b[39m     refresh_per_second=refresh_per_second,\n\u001b[32m     41\u001b[39m     transient=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     42\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\rich\\spinner.py:37\u001b[39m, in \u001b[36mSpinner.__init__\u001b[39m\u001b[34m(self, name, text, style, speed)\u001b[39m\n\u001b[32m     35\u001b[39m     spinner = SPINNERS[name]\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mno spinner called \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     38\u001b[39m \u001b[38;5;28mself\u001b[39m.text: \u001b[33m\"\u001b[39m\u001b[33mUnion[RenderableType, Text]\u001b[39m\u001b[33m\"\u001b[39m = (\n\u001b[32m     39\u001b[39m     Text.from_markup(text) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[32m     40\u001b[39m )\n\u001b[32m     41\u001b[39m \u001b[38;5;28mself\u001b[39m.name = name\n",
      "\u001b[31mKeyError\u001b[39m: \"no spinner called 'scale'\"",
      "During task with name 'reviewer_node' and id 'a9d7ac39-ab59-91da-f577-01494f02c9e3'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Literal\n",
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "\n",
    "# (Assuming your API keys and imports from the previous cell are still active)\n",
    "console = Console()\n",
    "\n",
    "# --- 1. THE REVIEWER NODE ---\n",
    "def reviewer_node(state: AgentState):\n",
    "    \"\"\"Acts as the 'Judge' to check for technical accuracy.\"\"\"\n",
    "    # Safety check: ensure there is a message to review\n",
    "    if not state[\"messages\"]:\n",
    "        return {\"messages\": [HumanMessage(content=\"No report found to review.\")]}\n",
    "        \n",
    "    report = state[\"messages\"][-1].content\n",
    "    # FIX: Changed spinner=\"scale\" to spinner=\"dots\"\n",
    "    with console.status(\"[bold yellow]⚖️ NVIDIA AI-Q is auditing the report...\", spinner=\"dots\"):\n",
    "        prompt = f\"\"\"\n",
    "        Act as a Senior NVIDIA Engineer. Review this report for technical accuracy:\n",
    "        {report}\n",
    "        \n",
    "        Is the comparison between Blackwell and Hopper complete? \n",
    "        Does it include thermal, power, and TFLOPS data?\n",
    "        If anything is missing, list it. If it's perfect, say 'APPROVED'.\n",
    "        \"\"\"\n",
    "        response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# --- 2. THE QUALITY GATE (The Router) ---\n",
    "def quality_gate(state: AgentState) -> Literal[\"researcher_node\", \"END\"]:\n",
    "    \"\"\"Decides if we need more research or if we are finished.\"\"\"\n",
    "    last_message = state[\"messages\"][-1].content\n",
    "    \n",
    "    if \"APPROVED\" in last_message.upper():\n",
    "        console.print(\"[bold green]✅ Report Verified and Approved by AI-Q Audit.\")\n",
    "        return END\n",
    "    else:\n",
    "        console.print(\"[bold red]❌ Audit Failed. Re-searching for missing details...\")\n",
    "        return \"researcher_node\"\n",
    "\n",
    "# --- 3. RE-ASSEMBLING THE GRAPH ---\n",
    "# (We add the Reviewer into your existing workflow)\n",
    "builder = StateGraph(AgentState)\n",
    "\n",
    "builder.add_node(\"planner_node\", planner_node)\n",
    "builder.add_node(\"researcher_node\", researcher_node)\n",
    "builder.add_node(\"writer_node\", writer_node)\n",
    "builder.add_node(\"reviewer_node\", reviewer_node)\n",
    "\n",
    "builder.add_edge(START, \"planner_node\")\n",
    "builder.add_edge(\"planner_node\", \"researcher_node\")\n",
    "builder.add_edge(\"researcher_node\", \"writer_node\")\n",
    "builder.add_edge(\"writer_node\", \"reviewer_node\")\n",
    "\n",
    "# This is the \"Deep\" part: The agent can loop back to research if the reviewer is unhappy\n",
    "builder.add_conditional_edges(\"reviewer_node\", quality_gate, {\n",
    "    \"researcher_node\": \"researcher_node\",\n",
    "    END: END\n",
    "})\n",
    "\n",
    "app_v2 = builder.compile()\n",
    "\n",
    "# --- 4. EXECUTION ---\n",
    "user_query = \"Detailed comparison: NVIDIA Blackwell B200 vs H100 NVLink bandwidth and energy efficiency.\"\n",
    "console.rule(\"[bold blue]NVIDIA AI-Q v2: DEEP VERIFICATION MODE\")\n",
    "app_v2.invoke({\"messages\": [HumanMessage(content=user_query)]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
