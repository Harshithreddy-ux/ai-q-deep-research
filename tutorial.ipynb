{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a99ce2f",
   "metadata": {},
   "source": [
    "# Deep Research Agent — Quick Tutorial\n",
    "\n",
    "This notebook shows how to run the lightweight training scaffold, call the FastAPI agent, and use the Streamlit UI. Keep a terminal handy for background services.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d122cf",
   "metadata": {},
   "source": [
    "## 1) Environment & Imports\n",
    "\n",
    "Install dependencies in the project's virtual environment and import key libraries.\n",
    "\n",
    "```bash\n",
    "python -m venv .venv\n",
    ".venv\\Scripts\\activate\n",
    "python -m pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Python checks (run in a cell):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac307ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "```python\n",
    "import sys\n",
    "import platform\n",
    "import torch\n",
    "import requests\n",
    "\n",
    "print('Python', sys.version)\n",
    "print('Platform', platform.platform())\n",
    "print('Torch', torch.__version__)\n",
    "print('Requests', requests.__version__)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657963ef",
   "metadata": {},
   "source": [
    "## 2) Project Configuration (VSCode)\n",
    "\n",
    "- Use the integrated terminal to run the Streamlit app and FastAPI backend.\n",
    "- Sample `tasks.json` / `launch.json` are included in the repo's README — use them to run/debug the server and notebook cells.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad46437f",
   "metadata": {},
   "source": [
    "## 3) Data Loading\n",
    "\n",
    "The repository stores run history in `runs.json`. We can load and preview recent runs.\n",
    "\n",
    "```python\n",
    "import json\n",
    "from pathlib import Path\n",
    "p = Path('runs.json')\n",
    "if p.exists():\n",
    "    runs = json.loads(p.read_text(encoding='utf-8'))\n",
    "    print('Total runs:', len(runs))\n",
    "    display(runs[:3])\n",
    "else:\n",
    "    print('No runs.json found (run the UI to create runs).')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113b7494",
   "metadata": {},
   "source": [
    "## 4) Data Preprocessing\n",
    "\n",
    "Add any preprocessing steps you need for your dataset. For the synthetic dataset used by the trainer no preprocessing is required. Example placeholder:\n",
    "\n",
    "```python\n",
    "def preprocess_text(s: str):\n",
    "    s = s.lower().strip()\n",
    "    return s\n",
    "\n",
    "# example\n",
    "print(preprocess_text('  Hello WORLD  '))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba919452",
   "metadata": {},
   "source": [
    "## 5) Core Functions / Agent API Example\n",
    "\n",
    "POST to the FastAPI `/run` endpoint to run a topic synchronously.\n",
    "\n",
    "```python\n",
    "import requests\n",
    "url = 'http://127.0.0.1:8000/run'\n",
    "resp = requests.post(url, json={'topic': 'Compare NVLink topologies'})\n",
    "print(resp.status_code)\n",
    "print(resp.json())\n",
    "```\n",
    "\n",
    "WebSocket example (async) to receive streaming messages from `/ws/run`:\n",
    "\n",
    "```python\n",
    "import asyncio, websockets, json\n",
    "\n",
    "async def ws_run(topic):\n",
    "    uri = 'ws://127.0.0.1:8000/ws/run'\n",
    "    async with websockets.connect(uri) as ws:\n",
    "        await ws.send(json.dumps({'topic': topic}))\n",
    "        try:\n",
    "            async for msg in ws:\n",
    "                print('MSG:', msg)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "# asyncio.run(ws_run('Compare NVLink topologies'))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc48675",
   "metadata": {},
   "source": [
    "## 6) Processing Pipeline / Model Training\n",
    "\n",
    "Run the tiny training scaffold from the repo. Example - **dry run** (quick):\n",
    "\n",
    "```bash\n",
    "python train/train.py --dry-run\n",
    "```\n",
    "\n",
    "Run a short training run and view TensorBoard:\n",
    "\n",
    "```bash\n",
    "python train/train.py --epochs 3 --batch-size 16\n",
    "tensorboard --logdir runs --port 6006\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3fc723",
   "metadata": {},
   "source": [
    "## 7) Evaluation & Metrics\n",
    "\n",
    "For the tiny LM we track training/validation loss. For the agent (LLM-based) evaluation, collect human ratings for relevance and completeness.\n",
    "\n",
    "(Example evaluation code would go here if you have labeled data.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca70fed",
   "metadata": {},
   "source": [
    "## 8) Visualization\n",
    "\n",
    "You can open TensorBoard to inspect training curves (see above). For agent outputs use `display()` or `print()` for quick inspection inside the notebook.\n",
    "\n",
    "```python\n",
    "# show last saved run report (if exists)\n",
    "from pathlib import Path\n",
    "p = Path('runs.json')\n",
    "if p.exists():\n",
    "    import json\n",
    "    runs = json.loads(p.read_text())\n",
    "    from IPython.display import Markdown\n",
    "    if runs:\n",
    "        display(Markdown(runs[0]['report'][:1000]))\n",
    "else:\n",
    "    print('No runs to show.')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fabf616",
   "metadata": {},
   "source": [
    "## 9) Unit Tests & Test Runner\n",
    "\n",
    "Add `pytest` tests in `tests/` for core functions. Example quick test to validate dataset shapes:\n",
    "\n",
    "```python\n",
    "# tests/test_dataset.py\n",
    "from train.dataset import SyntheticSeqDataset\n",
    "\n",
    "def test_dataset_len_and_shape():\n",
    "    ds = SyntheticSeqDataset(num_samples=10, seq_len=16, vocab_size=100)\n",
    "    x,y = ds[0]\n",
    "    assert len(ds) == 10\n",
    "    assert x.shape[0] == 16\n",
    "    assert y.shape[0] == 16\n",
    "```\n",
    "\n",
    "Run tests:\n",
    "```bash\n",
    "python -m pytest -q\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24d6b4e",
   "metadata": {},
   "source": [
    "## 10) Save, Export & Reproducibility\n",
    "\n",
    "Save artifacts with `torch.save` or `joblib` and record versions and seed.\n",
    "\n",
    "```python\n",
    "import json, torch, random, numpy as np\n",
    "meta = {\n",
    "    'seed': 42,\n",
    "}\n",
    "random.seed(meta['seed'])\n",
    "np.random.seed(meta['seed'])\n",
    "torch.manual_seed(meta['seed'])\n",
    "\n",
    "# Example: load a checkpoint\n",
    "from pathlib import Path\n",
    "ck = Path('checkpoints/ckpt_epoch_1.pt')\n",
    "if ck.exists():\n",
    "    d = torch.load(ck)\n",
    "    print('Loaded checkpoint, epoch=', d.get('epoch'))\n",
    "else:\n",
    "    print('No checkpoint found.')\n",
    "\n",
    "# Save experiment metadata\n",
    "Path('experiment_meta.json').write_text(json.dumps({'seed': meta['seed']}))\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
